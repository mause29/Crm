# üöÄ Optimizaciones de Rendimiento

Este documento describe las optimizaciones de rendimiento implementadas en el sistema CRM, incluyendo paginaci√≥n, cach√© y monitoreo de rendimiento.

## üìã Caracter√≠sticas Implementadas

### 1. Paginaci√≥n Inteligente

**Archivo:** `backend/app/routes/users_paginated.py`

#### Caracter√≠sticas:
- **Paginaci√≥n eficiente** para grandes vol√∫menes de datos
- **Par√°metros configurables:**
  - `page`: N√∫mero de p√°gina (por defecto: 1)
  - `per_page`: Elementos por p√°gina (1-100, por defecto: 10)
  - `active_only`: Solo usuarios activos (por defecto: true)
  - `role`: Filtrar por rol espec√≠fico

#### Ejemplo de uso:
```bash
GET /users/?page=2&per_page=20&active_only=true&role=admin
```

#### Respuesta paginada:
```json
{
  "items": [...],
  "pagination": {
    "page": 2,
    "per_page": 20,
    "total": 150,
    "total_pages": 8,
    "has_next": true,
    "has_prev": true
  }
}
```

### 2. Sistema de Cach√© Avanzado

**Archivo:** `backend/app/utils/cache.py`

#### Caracter√≠sticas:
- **Cach√© en memoria** con Redis como backend opcional
- **TTL configurable** por tipo de dato
- **Invalidaci√≥n inteligente** de cach√©
- **Compresi√≥n autom√°tica** para respuestas grandes

#### Configuraci√≥n de cach√©:
```python
# En settings.py
CACHE_TTL_USERS = 300  # 5 minutos
CACHE_TTL_CLIENTS = 600  # 10 minutos
CACHE_TTL_REPORTS = 1800  # 30 minutos
```

#### Funciones principales:
- `get_cached_user_list()`: Obtiene lista de usuarios del cach√©
- `set_cached_user_list()`: Almacena lista de usuarios en cach√©
- `invalidate_user_cache()`: Invalida cach√© de usuarios

### 3. Monitoreo de Rendimiento

**Archivo:** `backend/app/utils/performance.py`

#### Caracter√≠sticas:
- **Monitoreo en tiempo real** de endpoints
- **M√©tricas de sistema** (CPU, memoria, disco)
- **Estad√≠sticas de rendimiento** por endpoint
- **Percentiles P95/P99** para an√°lisis de latencia

#### Endpoints de monitoreo:
```bash
GET /performance/stats  # Estad√≠sticas detalladas
GET /health            # Verificaci√≥n de salud
```

#### M√©tricas disponibles:
- **Tiempo de respuesta promedio**
- **Percentiles P95 y P99**
- **N√∫mero total de requests**
- **Uso de recursos del sistema**

### 4. Optimizaci√≥n de Consultas

**Caracter√≠sticas:**
- **Consultas optimizadas** con √≠ndices apropiados
- **Timeout de consultas** para prevenir bloqueos
- **Pool de conexiones** configurado para alto rendimiento
- **Compresi√≥n de respuestas** autom√°tica

#### Configuraci√≥n de base de datos:
```python
db_config = {
    "pool_pre_ping": True,      # Verificar conexiones
    "pool_recycle": 3600,       # Reciclar cada hora
    "pool_size": 10,            # Tama√±o del pool
    "max_overflow": 20,         # Overflow m√°ximo
    "pool_timeout": 30,         # Timeout del pool
}
```

## üõ†Ô∏è Instalaci√≥n y Configuraci√≥n

### 1. Instalar dependencias
```bash
pip install -r backend/requirements-performance.txt
```

### 2. Configurar Redis (opcional)
```bash
# Instalar Redis
sudo apt-get install redis-server

# Iniciar Redis
redis-server

# Configurar en settings.py
REDIS_URL = "redis://localhost:6379"
USE_REDIS_CACHE = True
```

### 3. Configurar variables de entorno
```bash
# En .env
CACHE_TTL_USERS=300
CACHE_TTL_CLIENTS=600
DEFAULT_PAGE_SIZE=10
MAX_PAGE_SIZE=100
```

## üìä Uso y Monitoreo

### Verificar rendimiento
```bash
# Estad√≠sticas de rendimiento
curl http://localhost:8000/performance/stats

# Verificaci√≥n de salud
curl http://localhost:8000/health
```

### Monitoreo en producci√≥n
```python
from backend.app.utils.performance import performance_monitor

# Obtener m√©tricas
stats = await get_performance_stats()
print(f"CPU Usage: {stats['system']['cpu_percent']}%")
print(f"Memory Usage: {stats['system']['memory_percent']}%")
```

## üîß Optimizaciones Adicionales

### 1. Compresi√≥n de Respuestas
```python
from backend.app.utils.performance import CompressedJSONResponse

@app.get("/large-data")
async def get_large_data():
    data = await fetch_large_dataset()
    return CompressedJSONResponse(content=data)
```

### 2. Procesamiento As√≠ncrono por Lotes
```python
from backend.app.utils.performance import async_batch_processor

# Procesar datos en lotes
results = await async_batch_processor(
    items=large_dataset,
    processor=process_item,
    batch_size=10
)
```

### 3. Optimizaci√≥n de Memoria
```python
from backend.app.utils.performance import memory_efficient_iterator

# Iterar eficientemente sobre datos grandes
for batch in memory_efficient_iterator(large_list, chunk_size=100):
    await process_batch(batch)
```

## üìà Mejoras de Rendimiento Esperadas

### Antes de la optimizaci√≥n:
- **Tiempo de respuesta:** ~500-1000ms para listas grandes
- **Uso de memoria:** Alto para datasets grandes
- **Escalabilidad:** Limitada por consultas N+1

### Despu√©s de la optimizaci√≥n:
- **Tiempo de respuesta:** ~50-200ms con cach√©
- **Uso de memoria:** Optimizado con paginaci√≥n
- **Escalabilidad:** Mejorada con pool de conexiones
- **Disponibilidad:** Monitoreo proactivo

## üö® Alertas y Monitoreo

### M√©tricas cr√≠ticas a monitorear:
- **Tiempo de respuesta > 500ms**
- **Uso de CPU > 80%**
- **Uso de memoria > 85%**
- **Errores de cach√© > 5%**

### Configuraci√≥n de alertas:
```python
# En settings.py
ALERT_RESPONSE_TIME_THRESHOLD = 500  # ms
ALERT_CPU_THRESHOLD = 80  # %
ALERT_MEMORY_THRESHOLD = 85  # %
ALERT_CACHE_ERROR_THRESHOLD = 5  # %
```

## üîç Troubleshooting

### Problemas comunes:

1. **Cach√© no funciona:**
   - Verificar configuraci√≥n de Redis
   - Comprobar conectividad a Redis
   - Revisar logs de errores

2. **Consultas lentas:**
   - Verificar √≠ndices de base de datos
   - Comprobar configuraci√≥n del pool
   - Analizar queries con EXPLAIN

3. **Alto uso de memoria:**
   - Implementar paginaci√≥n
   - Usar iteradores eficientes
   - Configurar l√≠mites de memoria

4. **Timeouts de conexi√≥n:**
   - Ajustar configuraci√≥n del pool
   - Implementar retry logic
   - Configurar timeouts apropiados

## üìö Referencias

- [FastAPI Performance Tips](https://fastapi.tiangolo.com/tutorial/performance/)
- [SQLAlchemy Optimization](https://docs.sqlalchemy.org/en/14/faq/performance.html)
- [Redis Caching Patterns](https://redis.io/documentation)
- [Python AsyncIO Best Practices](https://docs.python.org/3/library/asyncio.html)

## ü§ù Contribuci√≥n

Para contribuir con optimizaciones adicionales:

1. **Medir antes y despu√©s** de cualquier cambio
2. **Documentar mejoras** en este archivo
3. **Agregar tests** para nuevas funcionalidades
4. **Actualizar m√©tricas** de monitoreo

---

*√öltima actualizaci√≥n: Diciembre 2024*
